{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"p62pEt3MrS2E"},"outputs":[],"source":["# Source:\n","# https://huggingface.co/datasets/aadityaubhat/GPT-wiki-intro/viewer/default/train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17758,"status":"ok","timestamp":1705640988093,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"yOmT1ILVXddw","outputId":"61d02c91-c23a-4847-ef47-24c1ef415368"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.2)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.36.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.26.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Upgrade pip\n","!pip install --upgrade pip\n","\n","# Install required packages\n","!pip install datasets transformers torch scikit-learn accelerate\n","\n","# If you specifically need the 'torch' extras from transformers\n","!pip install transformers[torch] --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JB_v3qlOXtGp"},"outputs":[],"source":["from datasets import load_dataset\n","import pandas as pd\n","import torch\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, DistilBertConfig, TrainerCallback\n","from torch.utils.data import Dataset\n","import os\n","import gc\n","from datetime import datetime\n","import subprocess\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, roc_auc_score, f1_score\n","import numpy as np\n","import json\n","import shutil"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1664,"status":"ok","timestamp":1705640989754,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"cZArTlG_YD6s","outputId":"6b31a9c8-3913-441f-fdef-a63924a40432"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Import the 'drive' module from the 'google.colab' library\n","# This module allows you to mount your Google Drive in the Colab environment.\n","# Make sure you have the necessary authorization to access your Drive.\n","# If not already installed, you may need to install the 'google-colab' package.\n","from google.colab import drive\n","\n","# Mount Google Drive to '/content/drive'\n","# This will make your Google Drive files accessible from within the Colab environment.\n","# You'll be prompted to authenticate and grant necessary permissions.\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WhLTxdT1YEFi"},"outputs":[],"source":["# Define paths\n","trained_model = \"wiki\"\n","training_data_used = \"wiki\"\n","# These variables store the paths to different directories and files.\n","# They are used for organization and to ensure you have the correct paths when needed.\n","base_path = \"/content/drive/My Drive/ColabData\"\n","checkpoint_path = f\"{base_path}/checkpoints\"\n","trained_model_path = f\"{base_path}/{trained_model}\"\n","new_model_path = f\"{base_path}/{training_data_used}\"\n","logs_path = f\"{base_path}/logs\"\n","csv_path = f\"{base_path}/wiki_data.csv\"\n","subset_paths = [f\"{base_path}/subset_{i}.csv\" for i in range(1, 5)]  # For training subsets and validation set\n","\n","# Create directories if they don't exist\n","# This section checks if the specified directories exist, and if not, it creates them.\n","os.makedirs(base_path, exist_ok=True)\n","os.makedirs(checkpoint_path, exist_ok=True)\n","os.makedirs(trained_model_path, exist_ok=True)\n","os.makedirs(logs_path, exist_ok=True)\n","\n","# Check if the main CSV file exists and load or create it\n","# This code checks if the main CSV file (wiki_data.csv) exists. If not, it loads data from a specified source\n","# and saves it as a CSV file in the specified directory on Google Drive.\n","if not os.path.exists(csv_path):\n","    # Load data from directory on huggingface.co\n","    dataset = load_dataset(\"aadityaubhat/GPT-wiki-intro\")\n","\n","    # Combine all splits into one DataFrame\n","    df = pd.concat([dataset[split].to_pandas() for split in dataset.keys()])\n","\n","    # Save the DataFrame as a CSV file in the specified directory on Google Drive\n","    df.to_csv(csv_path, index=False)\n","else:\n","    # Load the DataFrame from the CSV file\n","    df = pd.read_csv(csv_path)\n","\n","# Split the data into training and validation sets\n","# Here, the main DataFrame is split into a training set (df_subset) and a validation set (val_dataset).\n","df_subset, val_dataset = train_test_split(df, test_size=0.1, random_state=42)\n","\n","# Save the validation set as a separate CSV file\n","val_dataset.to_csv(f\"{base_path}/validation_set.csv\", index=False)\n","\n","# Check if subsets already exist, if not create and save them\n","# This section checks if the training subsets (subset_1.csv, subset_2.csv, subset_3.csv) exist.\n","# If not, it splits the training data into these subsets and saves them as CSV files.\n","if not all(os.path.exists(path) for path in subset_paths):\n","    split_size = len(df_subset) // 4\n","    for i, subset_path in enumerate(subset_paths):\n","        subset = df_subset.iloc[i*split_size: (i+1)*split_size]\n","        subset.to_csv(subset_path, index=False)\n","\n","    # Free memory by deleting the original DataFrame and performing garbage collection\n","    del df\n","    gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIil8FW9XjAG"},"outputs":[],"source":["# Define dataset class\n","class TextDataset(torch.utils.data.Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_length=512):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","\n","        # Tokenize the text on-the-fly\n","        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n","\n","        # Convert the encoding to a format suitable for PyTorch\n","        item = {key: val.squeeze(0) for key, val in encoding.items()}  # Squeeze is used to remove batch dimension\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def get_labels(self):\n","        return self.labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gglk9aXdmeRY"},"outputs":[],"source":["# Function to Calculate Metrics\n","def calculate_evaluation_metrics(predictions, true_labels):\n","    accuracy = accuracy_score(true_labels, predictions)\n","    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n","    conf_matrix = confusion_matrix(true_labels, predictions)\n","    roc_auc = roc_auc_score(true_labels, predictions)  # For binary classification\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'F1_score': f1,\n","        'confusion_matrix': conf_matrix.tolist(),\n","        'ROC_AUC': roc_auc\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q8UWAmlrkX7f"},"outputs":[],"source":["# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=checkpoint_path,\n","    num_train_epochs=1,                    # Number of training epochs (You may adjust this)\n","    per_device_train_batch_size=16,        # Batch size per GPU (Adjust based on your GPU memory)\n","    gradient_accumulation_steps=2,         # Increase if using a larger effective batch size\n","    evaluation_strategy=\"epoch\",           # Evaluation frequency (e.g., \"steps\" or \"epoch\")\n","    logging_dir=logs_path,                 # Directory for logs\n","    logging_steps=50,                      # Log training progress every N steps\n","    save_strategy=\"epoch\",                 # Save checkpoints every N epochs\n","    load_best_model_at_end=True,           # Load the best model at the end of training\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1705641135778,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"xXJYXn1n9Mr2","outputId":"6d702fe6-93ea-4942-ded0-d8bf843ec30a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Preparing training data.\n","Preparing validation data for final evaluation.\n"]}],"source":["# Training\n","print(\"Preparing training data.\")\n","\n","# Define a function to prepare training datasets\n","def prepare_training_data(df_subset):\n","    train_labels = [0] * len(df_subset['wiki_intro']) + [1] * len(df_subset['generated_intro'])\n","    train_texts = df_subset['wiki_intro'].tolist() + df_subset['generated_intro'].tolist()\n","\n","    # Create a training dataset using the TextDataset class\n","    train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n","    return train_dataset\n","\n","# Evaluation\n","print(\"Preparing validation data for final evaluation.\")\n","\n","# Define a function to prepare validation datasets\n","def prepare_validation_data(val_dataset):\n","    val_labels = [0] * len(val_dataset['wiki_intro']) + [1] * len(val_dataset['generated_intro'])\n","    val_texts = val_dataset['wiki_intro'].tolist() + val_dataset['generated_intro'].tolist()\n","\n","    # Create a validation dataset using the TextDataset class\n","    val_dataset = TextDataset(val_texts, val_labels, tokenizer)\n","    return val_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":822,"referenced_widgets":["18d8dac1ecc645c8a962bf088898999e","1e57363ba69047479d834541297eeee9","d5191d12ce30428cb90418b1d5c5bd7d","b5c6f52da70b4331ae58203b65c36206","c811f527ab96404c8cba2181a2e566e4","d6a1ad629a6f4a4fbe36e56c888c9a8b","976d2ed002f1448fb3851a54e5a35c05","6e52720c236b4d4eb1fba09e9f2bb31d","ea3933141d7e4529bd8211c90a37016a","3d032959d3414d36b5ede9368d24ef78","d58fceb580f2443ca7ba6e9fcdae9be6","62e94d4608b34229beeb700d40c3c6c8","e796ef311e3b48b19853ea99063b5b30","db5e6327faef43d281b38de6ebba168c","e2c4a0427b564a20b480060741668d93","24c215be2cc745d8b59de167059b0497","5c4792e45cb5451099467885d7b19550","b575e135a90b4f0fba7b8b3aff17495b","7b19d7d7359d492195229d63e8fe3f96","8858f68b400548f5ace1082912619fb0","c66312778e424c0e9d258df8920eff26","722ecfaa191340bf8d5e23e1b77045d5","f5c7759e097f499f980f0828fb5950b8","2932336f6a1442b78962213d552b4dd8","5d7d2c2e9fe14cf8a240301769de4ff0","c1d1d78cb0714cbf9fdb9c703637cd59","370f1795a65a4035bd79516d3779217d","7e1e129bc7044920ab50a56989cbfcf1","fdddec4e7c2c480fbc584353008ac5b3","6f2662dc6cbf4411a013e1444ed1beae","dd14811f47a04dc19ee176196ccc5dad","312d37093e3a443b8a010f7b1b62c915","cf151b3b46844cba808fa0637d82237f","5b0f43531f394859888bb8390b81f23d","c8639be8ae504f23beedddb438456828","ecbef88c92bf4f36b31f64a60998667d","561ab86a74ad489d95199b7c659de3b2","e2f3436b55a84ea7937fa6fcf28837ba","b8a6a0e81992417eabdf97f97b793f38","d503d892c97841a58f878ec7949966e7","a16d0de7e4244eeab7b8e57317aba1bd","01b44e5e09c846b4a337bb1cf59aa445","34bb0d0922404a628e83a67ca4aa02d1","ee0908d1782a4e248ba36808af7b0c80","ebb2f1f4e05b4d48b6226cd4b4067b8d","72d4272f7fea445b9d10ca6209209134","511f43a6586e44e2aab8c420d1d57b8e","eced30c022354e08ba5830d9970a7f2d","077a20b9219b42ba83b9c4dcaebe138f","96a6fc9661344b5f9bd450813c6826df","646bee136e20409d865d91106bcad833","425094e62db040bf8a1c9616936972da","75fda1007ead469d98e1c463cd2901d2","76e639fd722043868ee4f498ca58ff3a","20f3ee60b7a348718062eabc922f261e"]},"executionInfo":{"elapsed":4984,"status":"ok","timestamp":1705641420208,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"gWZwCNhwXi90","outputId":"201e5863-9639-4760-bb60-d0ecb689fe16"},"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18d8dac1ecc645c8a962bf088898999e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62e94d4608b34229beeb700d40c3c6c8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5c7759e097f499f980f0828fb5950b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b0f43531f394859888bb8390b81f23d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebb2f1f4e05b4d48b6226cd4b4067b8d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Initialized a new model.\n","Model Configuration:\n","DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.36.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","Tokenizer Information:\n","DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n","\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}\n"]}],"source":["# Use a small, fast model for quick training (DistilBERT)\n","\n","# Check if a model checkpoint exists in your drive\n","if os.path.exists(trained_model_path) and os.listdir(trained_model_path):\n","    # If a pre-trained model checkpoint exists in the specified directory, load it\n","    print(f\"Loading model checkpoint from {trained_model_path}\")\n","    model = AutoModelForSequenceClassification.from_pretrained(trained_model_path)\n","    tokenizer = AutoTokenizer.from_pretrained(trained_model_path)\n","    print(\"Model checkpoint loaded successfully.\")\n","else:\n","    # If no pre-trained model checkpoint exists, initialize a new model\n","    model_name = \"distilbert-base-uncased\"\n","    config = DistilBertConfig.from_pretrained(model_name)\n","    config.num_labels = 2  # Assuming you have a binary classification task\n","    model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    print(\"Initialized a new model.\")\n","\n","# Print the model configuration for reference\n","print(f\"Model Configuration:\\n{model.config}\")\n","\n","# Print the tokenizer information\n","print(f\"Tokenizer Information:\\n{tokenizer}\")\n","\n","# Initialize the Trainer\n","trainer = Trainer(\n","    model=model,                 # Initially, set with the base model\n","    args=training_args,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1705641425688,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"JPf8M9yxjIS6","outputId":"11c6fe73-e943-41ab-c6a3-b9d3d91eb4be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation dataset size: 30000\n"]}],"source":["# Prepare the subsets for validation\n","val_dataset = prepare_validation_data(val_dataset)\n","\n","# Splitting 0.5% of data for training and another 0.5% for validation (optional)\n","# _, small_val_dataset = train_test_split(val_dataset, test_size=0.005, random_state=43)\n","# val_dataset = prepare_validation_data(small_val_dataset)\n","\n","# Verify Dataset Initialization\n","if val_dataset is None or len(val_dataset) == 0:\n","    raise ValueError(\"Validation dataset is empty or not initialized.\")\n","\n","# Debug prints to check datasets\n","print(\"Validation dataset size:\", len(val_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"5D24LXCiFZyb","outputId":"d2bb19f0-45c2-479b-f4db-8b0496848693"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting epoch: 1\n","Starting manual epoch 1/4\n","Loading and preparing data for subset 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Training dataset size: 67500\n","No checkpoint found for epoch 0, continuing with base model. Checkpoint directory: /content/drive/My Drive/ColabData/checkpoints/manual_epoch_0\n"]},{"output_type":"stream","name":"stderr","text":["You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='674' max='2109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 674/2109 17:04 < 36:28, 0.66 it/s, Epoch 0.32/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["# Define the number of manual epochs and initialize a list to store checkpoint paths\n","num_manual_epochs = 4  # Set the number of manual epochs\n","all_checkpoint_paths = []\n","epoch_metrics = {}\n","all_metrics_paths = []\n","\n","# Initialize the starting_epoch to 0\n","starting_epoch = 0\n","# Determine the starting epoch based on existing checkpoints\n","while True:\n","    starting_epoch += 1\n","    checkpoint_directory = f\"{checkpoint_path}/manual_epoch_{starting_epoch}\"\n","    if not os.path.exists(checkpoint_directory):\n","        break\n","\n","# Print the determined starting epoch\n","print(f\"Starting epoch: {starting_epoch}\")\n","\n","# Looping over the manual epochs starting from the determined epoch\n","for epoch in range(starting_epoch - 1, num_manual_epochs):\n","    # Correctly set checkpoint_directory for the current epoch\n","    checkpoint_directory = f\"{checkpoint_path}/manual_epoch_{epoch + 1}\"\n","    print(f\"Starting manual epoch {epoch + 1}/{num_manual_epochs}\")\n","\n","    # Determine subset index based on the epoch and starting_epoch\n","    subset_index = (epoch + 1) % len(subset_paths)  # Calculate the subset index\n","\n","    # Load and prepare data for the current epoch\n","    subset_path = subset_paths[subset_index]\n","    print(f\"Loading and preparing data for subset {subset_index}\")\n","    current_df = pd.read_csv(subset_path)\n","    current_train_dataset = prepare_training_data(current_df)\n","\n","    # Splitting 0.2% of data for training\n","    # _, small_train_dataset = train_test_split(current_df, test_size=0.002, random_state=42)\n","    # Prepare the subsets for training and validation\n","    # current_train_dataset = prepare_training_data(small_train_dataset)\n","\n","    # Verify Dataset Initialization\n","    if current_train_dataset is None or len(current_train_dataset) == 0:\n","        raise ValueError(\"Training dataset is empty or not initialized.\")\n","\n","    # Debug prints to check datasets\n","    print(\"Training dataset size:\", len(current_train_dataset))\n","\n","    # Check if the specific checkpoint for this epoch exists\n","    previous_checkpoint_directory = f\"{checkpoint_path}/manual_epoch_{epoch}\"\n","\n","    if os.path.exists(previous_checkpoint_directory) and epoch != 0:\n","        print(f\"Loading checkpoint for epoch {epoch + 1} from {previous_checkpoint_directory}\")\n","        model = AutoModelForSequenceClassification.from_pretrained(previous_checkpoint_directory)\n","        tokenizer = AutoTokenizer.from_pretrained(previous_checkpoint_directory)\n","        trainer.model = model\n","        trainer.tokenizer = tokenizer\n","    else:\n","        # If no specific checkpoint found, use the base DistilBERT model\n","        print(f\"No checkpoint found for epoch {epoch}, continuing with base model. Checkpoint directory: {previous_checkpoint_directory}\")\n","        model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", config=config)\n","        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","\n","    # Update the Trainer's datasets for the current epoch\n","    trainer.train_dataset = current_train_dataset\n","    trainer.eval_dataset = val_dataset\n","\n","    # Train the model for one epoch on the current dataset\n","    print(\"Starting training...\")\n","    trainer.train()\n","\n","    # # Optionally, evaluate the model after the epoch\n","    # print(\"Evaluating model after training on current subset.\")\n","    # results = trainer.evaluate()\n","    # print(f\"Evaluation results: {results}\")\n","\n","    # # Check if \"predictions\" and \"label_ids\" exist in the results dictionary\n","    # if 0 in results and 1 in results:\n","    #     predictions = np.argmax(results[\"predictions\"], axis=1)\n","    #     true_labels = results[\"label_ids\"]\n","    # else:\n","    #     print(\"Warning: Predictions and label_ids are not available for this evaluation.\")\n","    #     predictions = None\n","    #     true_labels = None\n","\n","    # # Calculate metrics if true_labels are available\n","    # if true_labels is not None:\n","    #     # Calculate metrics\n","    #     epoch_metrics = calculate_evaluation_metrics(predictions, true_labels)\n","    # else:\n","    #     # Handle the case when true_labels is None (e.g., print a message or skip metrics calculation)\n","    #     print(\"True labels are not available for this evaluation.\")\n","\n","    # After completing the training for the current epoch, save the model\n","    print(f\"Saving model and tokenizer after manual epoch {epoch + 1}, subset {subset_index + 1}\")\n","    trainer.save_model(checkpoint_directory)\n","    tokenizer.save_pretrained(checkpoint_directory)\n","\n","    # Save metrics for this epoch\n","    metrics_path = f\"{logs_path}/metrics_epoch_{epoch + 1}.json\"\n","    with open(metrics_path, 'w') as file:\n","        json.dump(epoch_metrics, file, indent=4)\n","\n","    # Add the path to the metrics file to the list for later use\n","    all_metrics_paths.append(metrics_path)\n","\n","    # Add the checkpoint directory to the list\n","    all_checkpoint_paths.append(checkpoint_directory)\n","\n","    # Free up memory\n","    print(\"Freeing up memory.\")\n","    del current_df, current_train_dataset\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","print(\"Training process complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QJ8QXG9OpQ5W"},"outputs":[],"source":["# After completing all epochs, save the final model state\n","final_checkpoint_directory = f\"{new_model_path}\"\n","print(f\"Saving final model and tokenizer to {final_checkpoint_directory}\")\n","\n","# Save the final model and tokenizer\n","trainer.save_model(final_checkpoint_directory)\n","tokenizer.save_pretrained(final_checkpoint_directory)\n","\n","# Clean up intermediate checkpoint directories\n","# for i in range(num_manual_epochs):\n","#     checkpoint_directory = f\"{checkpoint_path}/manual_epoch_{i + 1}\"\n","#     if os.path.exists(checkpoint_directory):\n","#         shutil.rmtree(checkpoint_directory)\n","#         print(f\"Deleted checkpoint directory: {checkpoint_directory}\")\n","\n","print(\"Final model and checkpoint directories saved. Intermediate checkpoints deleted.\")\n","\n","if os.path.exists(checkpoint_path):\n","    shutil.rmtree(checkpoint_path)\n","    print(f\"Deleted entire checkpoint directory: {checkpoint_path}\")\n","os.makedirs(checkpoint_path, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tluIA7j4bZhb"},"outputs":[],"source":["# Function to initialize the Trainer for evaluation\n","def initialize_trainer_for_evaluation(model, training_args, eval_dataset):\n","    \"\"\"\n","    Initialize a Trainer object for model evaluation.\n","\n","    Args:\n","        model (PreTrainedModel): The pre-trained model to evaluate.\n","        training_args (TrainingArguments): Training arguments for evaluation.\n","        eval_dataset (Dataset): The evaluation dataset.\n","\n","    Returns:\n","        Trainer: A Trainer object for evaluation.\n","    \"\"\"\n","    return Trainer(\n","        model=model,\n","        args=training_args,\n","        eval_dataset=eval_dataset,\n","    )\n","\n","# Function to get the next available file name\n","def get_next_file_name(file_prefix):\n","    \"\"\"\n","    Get the next available file name by appending an index.\n","\n","    Args:\n","        file_prefix (str): The prefix for the file name.\n","\n","    Returns:\n","        str: The next available file name.\n","    \"\"\"\n","    index = 0\n","    while True:\n","        file_name = f\"{file_prefix}_{index}.json\"\n","        if not os.path.exists(file_name):\n","            return file_name\n","        index += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gSCuFEkN5Bw4"},"outputs":[],"source":["# Load the final model for evaluation after all epochs\n","final_model_path = all_checkpoint_paths[-1] if all_checkpoint_paths else None\n","\n","if final_model_path:\n","    print(\"Loading final model for evaluation from:\", final_checkpoint_directory)\n","    model = AutoModelForSequenceClassification.from_pretrained(final_checkpoint_directory, config=config)\n","    tokenizer = AutoTokenizer.from_pretrained(final_checkpoint_directory)\n","\n","    # Initialize the Trainer for final evaluation with the validation dataset\n","    eval_trainer = initialize_trainer_for_evaluation(model, training_args, val_dataset)\n","\n","    # Predict on the validation dataset\n","    print(\"Predicting on the validation dataset.\")\n","    predictions = eval_trainer.predict(val_dataset)\n","\n","    # Extract the predicted labels from the predictions\n","    final_predictions = np.argmax(predictions.predictions, axis=1)\n","    final_true_labels = val_dataset.get_labels()  # Get the true labels from the validation dataset\n","\n","    # Calculate final evaluation metrics\n","    final_metrics = calculate_evaluation_metrics(final_predictions, final_true_labels)\n","\n","    # Save final metrics with a sequentially numbered file name\n","    final_metrics_path = get_next_file_name(f\"{logs_path}/final_evaluation_metrics\")\n","    try:\n","        with open(final_metrics_path, 'w') as file:\n","            json.dump(final_metrics, file, indent=4)\n","            print(f\"Final Evaluation Metrics Saved as {final_metrics_path}\")\n","    except Exception as e:\n","        print(f\"An error occurred while saving the final metrics: {str(e)}\")\n","\n","    # Add the path to the final evaluation metrics file to the list for later use\n","    all_metrics_paths.append(final_metrics_path)\n","\n","    # Print the final evaluation metrics\n","    print(\"Final Evaluation Metrics:\")\n","    print(\"Accuracy:\", final_metrics['accuracy'])\n","    print(\"Precision:\", final_metrics['precision'])\n","    print(\"Recall:\", final_metrics['recall'])\n","    print(\"F1 Score:\", final_metrics['F1_score'])\n","    print(\"Confusion Matrix:\")\n","    print(final_metrics['confusion_matrix'])\n","    print(\"ROC AUC:\", final_metrics['ROC_AUC'])\n","\n","    # Print the last saved final metrics\n","    if os.path.exists(final_metrics_path):\n","        print(f\"Last Saved Final Metrics ({final_metrics_path}):\")\n","        with open(final_metrics_path, 'r') as file:\n","            last_saved_metrics = json.load(file)\n","            print(\"Accuracy:\", last_saved_metrics['accuracy'])\n","            print(\"Precision:\", last_saved_metrics['precision'])\n","            print(\"Recall:\", last_saved_metrics['recall'])\n","            print(\"F1 Score:\", last_saved_metrics['F1_score'])\n","            print(\"Confusion Matrix:\")\n","            print(last_saved_metrics['confusion_matrix'])\n","            print(\"ROC AUC:\", last_saved_metrics['ROC_AUC'])\n","else:\n","    print(\"No model checkpoint found for evaluation.\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/Di9mar/ada4b/blob/main/Wiki_Classification_2.ipynb","timestamp":1705642465587},{"file_id":"https://github.com/Di9mar/ada4b/blob/main/Wiki_Classification_2.ipynb","timestamp":1705637877793}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"18d8dac1ecc645c8a962bf088898999e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e57363ba69047479d834541297eeee9","IPY_MODEL_d5191d12ce30428cb90418b1d5c5bd7d","IPY_MODEL_b5c6f52da70b4331ae58203b65c36206"],"layout":"IPY_MODEL_c811f527ab96404c8cba2181a2e566e4"}},"1e57363ba69047479d834541297eeee9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6a1ad629a6f4a4fbe36e56c888c9a8b","placeholder":"​","style":"IPY_MODEL_976d2ed002f1448fb3851a54e5a35c05","value":"config.json: 100%"}},"d5191d12ce30428cb90418b1d5c5bd7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e52720c236b4d4eb1fba09e9f2bb31d","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea3933141d7e4529bd8211c90a37016a","value":483}},"b5c6f52da70b4331ae58203b65c36206":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d032959d3414d36b5ede9368d24ef78","placeholder":"​","style":"IPY_MODEL_d58fceb580f2443ca7ba6e9fcdae9be6","value":" 483/483 [00:00&lt;00:00, 32.4kB/s]"}},"c811f527ab96404c8cba2181a2e566e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6a1ad629a6f4a4fbe36e56c888c9a8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"976d2ed002f1448fb3851a54e5a35c05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e52720c236b4d4eb1fba09e9f2bb31d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea3933141d7e4529bd8211c90a37016a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d032959d3414d36b5ede9368d24ef78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d58fceb580f2443ca7ba6e9fcdae9be6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62e94d4608b34229beeb700d40c3c6c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e796ef311e3b48b19853ea99063b5b30","IPY_MODEL_db5e6327faef43d281b38de6ebba168c","IPY_MODEL_e2c4a0427b564a20b480060741668d93"],"layout":"IPY_MODEL_24c215be2cc745d8b59de167059b0497"}},"e796ef311e3b48b19853ea99063b5b30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c4792e45cb5451099467885d7b19550","placeholder":"​","style":"IPY_MODEL_b575e135a90b4f0fba7b8b3aff17495b","value":"model.safetensors: 100%"}},"db5e6327faef43d281b38de6ebba168c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b19d7d7359d492195229d63e8fe3f96","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8858f68b400548f5ace1082912619fb0","value":267954768}},"e2c4a0427b564a20b480060741668d93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c66312778e424c0e9d258df8920eff26","placeholder":"​","style":"IPY_MODEL_722ecfaa191340bf8d5e23e1b77045d5","value":" 268M/268M [00:02&lt;00:00, 135MB/s]"}},"24c215be2cc745d8b59de167059b0497":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c4792e45cb5451099467885d7b19550":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b575e135a90b4f0fba7b8b3aff17495b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b19d7d7359d492195229d63e8fe3f96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8858f68b400548f5ace1082912619fb0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c66312778e424c0e9d258df8920eff26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"722ecfaa191340bf8d5e23e1b77045d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5c7759e097f499f980f0828fb5950b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2932336f6a1442b78962213d552b4dd8","IPY_MODEL_5d7d2c2e9fe14cf8a240301769de4ff0","IPY_MODEL_c1d1d78cb0714cbf9fdb9c703637cd59"],"layout":"IPY_MODEL_370f1795a65a4035bd79516d3779217d"}},"2932336f6a1442b78962213d552b4dd8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e1e129bc7044920ab50a56989cbfcf1","placeholder":"​","style":"IPY_MODEL_fdddec4e7c2c480fbc584353008ac5b3","value":"tokenizer_config.json: 100%"}},"5d7d2c2e9fe14cf8a240301769de4ff0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f2662dc6cbf4411a013e1444ed1beae","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd14811f47a04dc19ee176196ccc5dad","value":28}},"c1d1d78cb0714cbf9fdb9c703637cd59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_312d37093e3a443b8a010f7b1b62c915","placeholder":"​","style":"IPY_MODEL_cf151b3b46844cba808fa0637d82237f","value":" 28.0/28.0 [00:00&lt;00:00, 2.19kB/s]"}},"370f1795a65a4035bd79516d3779217d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e1e129bc7044920ab50a56989cbfcf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdddec4e7c2c480fbc584353008ac5b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f2662dc6cbf4411a013e1444ed1beae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd14811f47a04dc19ee176196ccc5dad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"312d37093e3a443b8a010f7b1b62c915":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf151b3b46844cba808fa0637d82237f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b0f43531f394859888bb8390b81f23d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8639be8ae504f23beedddb438456828","IPY_MODEL_ecbef88c92bf4f36b31f64a60998667d","IPY_MODEL_561ab86a74ad489d95199b7c659de3b2"],"layout":"IPY_MODEL_e2f3436b55a84ea7937fa6fcf28837ba"}},"c8639be8ae504f23beedddb438456828":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8a6a0e81992417eabdf97f97b793f38","placeholder":"​","style":"IPY_MODEL_d503d892c97841a58f878ec7949966e7","value":"vocab.txt: 100%"}},"ecbef88c92bf4f36b31f64a60998667d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a16d0de7e4244eeab7b8e57317aba1bd","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01b44e5e09c846b4a337bb1cf59aa445","value":231508}},"561ab86a74ad489d95199b7c659de3b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34bb0d0922404a628e83a67ca4aa02d1","placeholder":"​","style":"IPY_MODEL_ee0908d1782a4e248ba36808af7b0c80","value":" 232k/232k [00:00&lt;00:00, 3.39MB/s]"}},"e2f3436b55a84ea7937fa6fcf28837ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8a6a0e81992417eabdf97f97b793f38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d503d892c97841a58f878ec7949966e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a16d0de7e4244eeab7b8e57317aba1bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01b44e5e09c846b4a337bb1cf59aa445":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34bb0d0922404a628e83a67ca4aa02d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee0908d1782a4e248ba36808af7b0c80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebb2f1f4e05b4d48b6226cd4b4067b8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72d4272f7fea445b9d10ca6209209134","IPY_MODEL_511f43a6586e44e2aab8c420d1d57b8e","IPY_MODEL_eced30c022354e08ba5830d9970a7f2d"],"layout":"IPY_MODEL_077a20b9219b42ba83b9c4dcaebe138f"}},"72d4272f7fea445b9d10ca6209209134":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96a6fc9661344b5f9bd450813c6826df","placeholder":"​","style":"IPY_MODEL_646bee136e20409d865d91106bcad833","value":"tokenizer.json: 100%"}},"511f43a6586e44e2aab8c420d1d57b8e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_425094e62db040bf8a1c9616936972da","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75fda1007ead469d98e1c463cd2901d2","value":466062}},"eced30c022354e08ba5830d9970a7f2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76e639fd722043868ee4f498ca58ff3a","placeholder":"​","style":"IPY_MODEL_20f3ee60b7a348718062eabc922f261e","value":" 466k/466k [00:00&lt;00:00, 6.25MB/s]"}},"077a20b9219b42ba83b9c4dcaebe138f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96a6fc9661344b5f9bd450813c6826df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"646bee136e20409d865d91106bcad833":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"425094e62db040bf8a1c9616936972da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75fda1007ead469d98e1c463cd2901d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76e639fd722043868ee4f498ca58ff3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20f3ee60b7a348718062eabc922f261e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}