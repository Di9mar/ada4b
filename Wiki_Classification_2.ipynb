{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/Di9mar/ada4b/blob/main/Wiki%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1705637367212,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"p62pEt3MrS2E"},"outputs":[],"source":["# Source:\n","# https://huggingface.co/datasets/aadityaubhat/GPT-wiki-intro/viewer/default/train"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42172,"status":"ok","timestamp":1705637409380,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"yOmT1ILVXddw","outputId":"612c984e-d6a0-4086-8398-e6bd4651e40d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.2)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.36.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.26.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Upgrade pip\n","!pip install --upgrade pip\n","\n","# Install required packages\n","!pip install datasets transformers torch scikit-learn accelerate\n","\n","# If you specifically need the 'torch' extras from transformers\n","!pip install transformers[torch] --upgrade"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1705637409381,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"JB_v3qlOXtGp"},"outputs":[],"source":["from datasets import load_dataset\n","import pandas as pd\n","import torch\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, DistilBertConfig, TrainerCallback\n","from torch.utils.data import Dataset\n","import os\n","import gc\n","from datetime import datetime\n","import subprocess\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, roc_auc_score, f1_score\n","import numpy as np\n","import json\n","import shutil"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1706,"status":"ok","timestamp":1705637411082,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"cZArTlG_YD6s","outputId":"ea046e0f-f0fb-4d6c-fad2-ed6af7bb951b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Import the 'drive' module from the 'google.colab' library\n","# This module allows you to mount your Google Drive in the Colab environment.\n","# Make sure you have the necessary authorization to access your Drive.\n","# If not already installed, you may need to install the 'google-colab' package.\n","from google.colab import drive\n","\n","# Mount Google Drive to '/content/drive'\n","# This will make your Google Drive files accessible from within the Colab environment.\n","# You'll be prompted to authenticate and grant necessary permissions.\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":20859,"status":"ok","timestamp":1705637431938,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"WhLTxdT1YEFi"},"outputs":[],"source":["# Define paths\n","trained_model = \"wiki\"\n","training_data_used = \"wiki\"\n","# These variables store the paths to different directories and files.\n","# They are used for organization and to ensure you have the correct paths when needed.\n","base_path = \"/content/drive/My Drive/ColabData\"\n","checkpoint_path = f\"{base_path}/checkpoints\"\n","trained_model_path = f\"{base_path}/{trained_model}\"\n","new_model_path = f\"{base_path}/{training_data_used}\"\n","logs_path = f\"{base_path}/logs\"\n","csv_path = f\"{base_path}/wiki_data.csv\"\n","subset_paths = [f\"{base_path}/subset_{i}.csv\" for i in range(1, 5)]  # For training subsets and validation set\n","\n","# Create directories if they don't exist\n","# This section checks if the specified directories exist, and if not, it creates them.\n","os.makedirs(base_path, exist_ok=True)\n","os.makedirs(checkpoint_path, exist_ok=True)\n","os.makedirs(trained_model_path, exist_ok=True)\n","os.makedirs(logs_path, exist_ok=True)\n","\n","# Check if the main CSV file exists and load or create it\n","# This code checks if the main CSV file (wiki_data.csv) exists. If not, it loads data from a specified source\n","# and saves it as a CSV file in the specified directory on Google Drive.\n","if not os.path.exists(csv_path):\n","    # Load data from directory on huggingface.co\n","    dataset = load_dataset(\"aadityaubhat/GPT-wiki-intro\")\n","\n","    # Combine all splits into one DataFrame\n","    df = pd.concat([dataset[split].to_pandas() for split in dataset.keys()])\n","\n","    # Save the DataFrame as a CSV file in the specified directory on Google Drive\n","    df.to_csv(csv_path, index=False)\n","else:\n","    # Load the DataFrame from the CSV file\n","    df = pd.read_csv(csv_path)\n","\n","# Split the data into training and validation sets\n","# Here, the main DataFrame is split into a training set (df_subset) and a validation set (val_dataset).\n","df_subset, val_dataset = train_test_split(df, test_size=0.1, random_state=42)\n","\n","# Save the validation set as a separate CSV file\n","val_dataset.to_csv(f\"{base_path}/validation_set.csv\", index=False)\n","\n","# Check if subsets already exist, if not create and save them\n","# This section checks if the training subsets (subset_1.csv, subset_2.csv, subset_3.csv) exist.\n","# If not, it splits the training data into these subsets and saves them as CSV files.\n","if not all(os.path.exists(path) for path in subset_paths):\n","    split_size = len(df_subset) // 4\n","    for i, subset_path in enumerate(subset_paths):\n","        subset = df_subset.iloc[i*split_size: (i+1)*split_size]\n","        subset.to_csv(subset_path, index=False)\n","\n","    # Free memory by deleting the original DataFrame and performing garbage collection\n","    del df\n","    gc.collect()"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1705637431938,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"yIil8FW9XjAG"},"outputs":[],"source":["# Define dataset class\n","class TextDataset(torch.utils.data.Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_length=512):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","\n","        # Tokenize the text on-the-fly\n","        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n","\n","        # Convert the encoding to a format suitable for PyTorch\n","        item = {key: val.squeeze(0) for key, val in encoding.items()}  # Squeeze is used to remove batch dimension\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def get_labels(self):\n","        return self.labels"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1705637431938,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"Gglk9aXdmeRY"},"outputs":[],"source":["# Function to Calculate Metrics\n","def calculate_evaluation_metrics(predictions, true_labels):\n","    accuracy = accuracy_score(true_labels, predictions)\n","    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n","    conf_matrix = confusion_matrix(true_labels, predictions)\n","    roc_auc = roc_auc_score(true_labels, predictions)  # For binary classification\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'F1_score': f1,\n","        'confusion_matrix': conf_matrix.tolist(),\n","        'ROC_AUC': roc_auc\n","    }"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1705637431938,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"q8UWAmlrkX7f"},"outputs":[],"source":["# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=checkpoint_path,\n","    num_train_epochs=1,                    # Number of training epochs (You may adjust this)\n","    per_device_train_batch_size=16,        # Batch size per GPU (Adjust based on your GPU memory)\n","    gradient_accumulation_steps=2,         # Increase if using a larger effective batch size\n","    evaluation_strategy=\"epoch\",           # Evaluation frequency (e.g., \"steps\" or \"epoch\")\n","    logging_dir=logs_path,                 # Directory for logs\n","    logging_steps=50,                      # Log training progress every N steps\n","    save_strategy=\"epoch\",                 # Save checkpoints every N epochs\n","    load_best_model_at_end=True,           # Load the best model at the end of training\n",")"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1705637431938,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"xXJYXn1n9Mr2","outputId":"4d20052c-f225-4ac6-b853-525d54eb76d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Preparing training data.\n","Preparing validation data for final evaluation.\n"]}],"source":["# Training\n","print(\"Preparing training data.\")\n","\n","# Define a function to prepare training datasets\n","def prepare_training_data(df_subset):\n","    train_labels = [0] * len(df_subset['wiki_intro']) + [1] * len(df_subset['generated_intro'])\n","    train_texts = df_subset['wiki_intro'].tolist() + df_subset['generated_intro'].tolist()\n","\n","    # Create a training dataset using the TextDataset class\n","    train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n","    return train_dataset\n","\n","# Evaluation\n","print(\"Preparing validation data for final evaluation.\")\n","\n","# Define a function to prepare validation datasets\n","def prepare_validation_data(val_dataset):\n","    val_texts = val_dataset['wiki_intro'].tolist() + val_dataset['generated_intro'].tolist()\n","    val_labels = [0] * len(val_dataset['wiki_intro']) + [1] * len(val_dataset['generated_intro'])\n","\n","    # Create a validation dataset using the TextDataset class\n","    val_dataset = TextDataset(val_texts, val_labels, tokenizer)\n","    return val_dataset"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"executionInfo":{"elapsed":234,"status":"error","timestamp":1705637652564,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"JPf8M9yxjIS6","outputId":"72e5cae1-c49f-4ecb-f6c6-0c03e1a05fbb"},"outputs":[{"ename":"NameError","evalue":"name 'tokenizer' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-97612b6611b4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prepare the subsets for validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_validation_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Splitting 0.5% of data for training and another 0.5% for validation (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# _, small_val_dataset = train_test_split(val_dataset, test_size=0.005, random_state=43)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-43-226f13b74ae4>\u001b[0m in \u001b[0;36mprepare_validation_data\u001b[0;34m(val_dataset)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Create a validation dataset using the TextDataset class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"]}],"source":["# Prepare the subsets for validation\n","val_dataset = prepare_validation_data(val_dataset)\n","\n","# Splitting 0.5% of data for training and another 0.5% for validation (optional)\n","# _, small_val_dataset = train_test_split(val_dataset, test_size=0.005, random_state=43)\n","# val_dataset = prepare_validation_data(small_val_dataset)\n","\n","# Verify Dataset Initialization\n","if val_dataset is None or len(val_dataset) == 0:\n","    raise ValueError(\"Validation dataset is empty or not initialized.\")\n","\n","# Debug prints to check datasets\n","print(\"Validation dataset size:\", len(val_dataset))"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":926,"referenced_widgets":["a1c230300e3a4d1abdf5be4122d172cd","a7810b5f94314f2f8d3b3c906f7360c9","59f8964f18224a8bb2d28683158d6a07","093d063d127846879a0ef654aa62333c","3ee48636612345cab59318136d6b0f11","80dc312638b34af6b835f7beeb8ad76a","32aa2fd53d22459d81a9b2181049900d","c6868385188f478f8f6294b6ae75bfa8","3a1155a215a6413292a6540cd351264c","0961f4f8c9d541479d287784a4435936","79928b2f3b074291b4e68ef428aafae1","f890ff6050fb4e1da53d9ffe3843646d","0c7e7f0e002543c7936104ec88ef89ee","9213b880c7f9410aa4b1bf6d70008806","4d4cad4a3ba541a4bda30aa87fd34467","5f09074ed4874d2bb181d95142d0ddfd","c07f242f8f6743efba7c594d36e4e012","ae4d9dedbdb34304acd0931f7837b1f4","fd6fb565203c4ff08d7b761456f7a11b","68f98b2a9af445f19fede336071d5db3","6457d495913548c6a6ea09923e36e41a","1b6c388243da41c58cdc3cc3ed3729f0","69230da3e92540ac88421f76cd669d3d","0e5a2d0ce53c46a2965f3e7aa01d28b3","12cdbd56e7f848e6a9df72c3dd2dc38f","450a478aa475494f9c342ebf9f75e694","82e261a44e5443249b9dc51f37e62c60","c18bedd594e54b708244427ef580781c","bc090c8c53b34fab8233a30d766947dd","97900e9795b94c2285b306d695fad939","0886563dfef64517b2830aca9e761843","ef37286e51e142269681109636618c19","29bc44c2e9b641a7b4258521fdda0827","bd1e92c5583f4699af5170a91305e466","fc51a4fe4bb24e8c8783ee287ca43159","9ca5b2c10aee41aa8b8fa0dc261f8565","87e48c43555441cf8d75bdbc785f24fe","2f29474cb4eb49ca8c14f20b99b961ce","4feab3a1edc64b05af0bde80439e57c0","5881ff5cedf946b09b440ed8b6cb5268","9babcbaca4ad41629b4162718822af13","e6d16375fd9d4d589b964f532c416642","59a758cf5dc34bde89f77b852b7be585","9f3dd424b6984361acc31b6e9a111ba4","284f3fbfc53041c580c2765166311072","f873e5aa492944049d4039593bedd22e","c1d3f98480bb4ef2902e80cc456fb420","bbad81ca2dcf43238e86b0becfb296ba","c96e1789aaa4449ba03fba7b663f2a4b","2f41f940f6b54a0a8a9d1088414a4ad7","32dc9ea09af2412e8e1d6230cf085701","d1983b1bff9b48f8871ce1c403a8af94","49270fa05084478c9ae69c26d6a6dbcf","44ba4b54afd4437884f091275d519938","8475363f9a3e4e7f92f5e49786b5ca4c"]},"executionInfo":{"elapsed":5934,"status":"ok","timestamp":1705637708226,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"gWZwCNhwXi90","outputId":"95b2f433-66ea-4c7f-fee6-a3d5630edf46"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1c230300e3a4d1abdf5be4122d172cd","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f890ff6050fb4e1da53d9ffe3843646d","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69230da3e92540ac88421f76cd669d3d","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd1e92c5583f4699af5170a91305e466","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"284f3fbfc53041c580c2765166311072","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Initialized a new model.\n","Model Configuration:\n","DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.36.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","Tokenizer Information:\n","DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n","\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}\n"]}],"source":["# Use a small, fast model for quick training (DistilBERT)\n","\n","# Check if a model checkpoint exists in your drive\n","if os.path.exists(trained_model_path) and os.listdir(trained_model_path):\n","    # If a pre-trained model checkpoint exists in the specified directory, load it\n","    print(f\"Loading model checkpoint from {trained_model_path}\")\n","    model = AutoModelForSequenceClassification.from_pretrained(trained_model_path)\n","    tokenizer = AutoTokenizer.from_pretrained(trained_model_path)\n","    print(\"Model checkpoint loaded successfully.\")\n","else:\n","    # If no pre-trained model checkpoint exists, initialize a new model\n","    model_name = \"distilbert-base-uncased\"\n","    config = DistilBertConfig.from_pretrained(model_name)\n","    config.num_labels = 2  # Assuming you have a binary classification task\n","    model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    print(\"Initialized a new model.\")\n","\n","# Print the model configuration for reference\n","print(f\"Model Configuration:\\n{model.config}\")\n","\n","# Print the tokenizer information\n","print(f\"Tokenizer Information:\\n{tokenizer}\")\n","\n","# Initialize the Trainer\n","trainer = Trainer(\n","    model=model,                 # Initially, set with the base model\n","    args=training_args,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer\n",")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"executionInfo":{"elapsed":265,"status":"error","timestamp":1705637861987,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"5D24LXCiFZyb","outputId":"f5102175-e671-41fc-911e-7a3873c468af"},"outputs":[{"ename":"NameError","evalue":"name 'checkpoint_path' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-2ffd31c9596d>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstarting_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcheckpoint_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{checkpoint_path}/manual_epoch_{starting_epoch}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'checkpoint_path' is not defined"]}],"source":["# Define the number of manual epochs and initialize a list to store checkpoint paths\n","num_manual_epochs = 4  # Set the number of manual epochs\n","all_checkpoint_paths = []\n","epoch_metrics = {}\n","all_metrics_paths = []\n","\n","# Initialize the starting_epoch to 0\n","starting_epoch = 0\n","# Determine the starting epoch based on existing checkpoints\n","while True:\n","    starting_epoch += 1\n","    checkpoint_directory = f\"{checkpoint_path}/manual_epoch_{starting_epoch}\"\n","    if not os.path.exists(checkpoint_directory):\n","        break\n","\n","# Print the determined starting epoch\n","print(f\"Starting epoch: {starting_epoch}\")\n","\n","# Looping over the manual epochs starting from the determined epoch\n","for epoch in range(starting_epoch - 1, num_manual_epochs):\n","    # Correctly set checkpoint_directory for the current epoch\n","    checkpoint_directory = f\"{checkpoint_path}/manual_epoch_{epoch + 1}\"\n","    print(f\"Starting manual epoch {epoch + 1}/{num_manual_epochs}\")\n","\n","    # Determine subset index based on the epoch and starting_epoch\n","    subset_index = (epoch + 1) % len(subset_paths)  # Calculate the subset index\n","\n","    # Load and prepare data for the current epoch\n","    subset_path = subset_paths[subset_index]\n","    print(f\"Loading and preparing data for subset {subset_index}\")\n","    current_df = pd.read_csv(subset_path)\n","    current_train_dataset = prepare_training_data(current_df)\n","\n","    # Splitting 0.2% of data for training\n","    # _, small_train_dataset = train_test_split(current_df, test_size=0.002, random_state=42)\n","    # Prepare the subsets for training and validation\n","    # current_train_dataset = prepare_training_data(small_train_dataset)\n","\n","    # Verify Dataset Initialization\n","    if current_train_dataset is None or len(current_train_dataset) == 0:\n","        raise ValueError(\"Training dataset is empty or not initialized.\")\n","\n","    # Debug prints to check datasets\n","    print(\"Training dataset size:\", len(current_train_dataset))\n","\n","    # Check if the specific checkpoint for this epoch exists\n","    previous_checkpoint_directory = f\"{checkpoint_path}/manual_epoch_{epoch}\"\n","\n","    if os.path.exists(previous_checkpoint_directory) and epoch != 0:\n","        print(f\"Loading checkpoint for epoch {epoch + 1} from {previous_checkpoint_directory}\")\n","        model = AutoModelForSequenceClassification.from_pretrained(previous_checkpoint_directory)\n","        tokenizer = AutoTokenizer.from_pretrained(previous_checkpoint_directory)\n","        trainer.model = model\n","        trainer.tokenizer = tokenizer\n","    else:\n","        # If no specific checkpoint found, use the base DistilBERT model\n","        print(f\"No checkpoint found for epoch {epoch}, continuing with base model. Checkpoint directory: {previous_checkpoint_directory}\")\n","        model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", config=config)\n","        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","\n","    # Update the Trainer's datasets for the current epoch\n","    trainer.train_dataset = current_train_dataset\n","    trainer.eval_dataset = val_dataset\n","\n","    # Train the model for one epoch on the current dataset\n","    print(\"Starting training...\")\n","    trainer.train()\n","\n","    # # Optionally, evaluate the model after the epoch\n","    # print(\"Evaluating model after training on current subset.\")\n","    # results = trainer.evaluate()\n","    # print(f\"Evaluation results: {results}\")\n","\n","    # # Check if \"predictions\" and \"label_ids\" exist in the results dictionary\n","    # if 0 in results and 1 in results:\n","    #     predictions = np.argmax(results[\"predictions\"], axis=1)\n","    #     true_labels = results[\"label_ids\"]\n","    # else:\n","    #     print(\"Warning: Predictions and label_ids are not available for this evaluation.\")\n","    #     predictions = None\n","    #     true_labels = None\n","\n","    # # Calculate metrics if true_labels are available\n","    # if true_labels is not None:\n","    #     # Calculate metrics\n","    #     epoch_metrics = calculate_evaluation_metrics(predictions, true_labels)\n","    # else:\n","    #     # Handle the case when true_labels is None (e.g., print a message or skip metrics calculation)\n","    #     print(\"True labels are not available for this evaluation.\")\n","\n","    # After completing the training for the current epoch, save the model\n","    print(f\"Saving model and tokenizer after manual epoch {epoch + 1}, subset {subset_index + 1}\")\n","    trainer.save_model(checkpoint_directory)\n","    tokenizer.save_pretrained(checkpoint_directory)\n","\n","    # Save metrics for this epoch\n","    metrics_path = f\"{logs_path}/metrics_epoch_{epoch + 1}.json\"\n","    with open(metrics_path, 'w') as file:\n","        json.dump(epoch_metrics, file, indent=4)\n","\n","    # Add the path to the metrics file to the list for later use\n","    all_metrics_paths.append(metrics_path)\n","\n","    # Add the checkpoint directory to the list\n","    all_checkpoint_paths.append(checkpoint_directory)\n","\n","    # Free up memory\n","    print(\"Freeing up memory.\")\n","    del current_df, current_train_dataset\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","print(\"Training process complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1705637432313,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"QJ8QXG9OpQ5W"},"outputs":[],"source":["# After completing all epochs, save the final model state\n","final_checkpoint_directory = f\"{new_model_path}\"\n","print(f\"Saving final model and tokenizer to {final_checkpoint_directory}\")\n","\n","# Save the final model and tokenizer\n","trainer.save_model(final_checkpoint_directory)\n","tokenizer.save_pretrained(final_checkpoint_directory)\n","\n","# Clean up intermediate checkpoint directories\n","# for i in range(num_manual_epochs):\n","#     checkpoint_directory = f\"{checkpoint_path}/manual_epoch_{i + 1}\"\n","#     if os.path.exists(checkpoint_directory):\n","#         shutil.rmtree(checkpoint_directory)\n","#         print(f\"Deleted checkpoint directory: {checkpoint_directory}\")\n","\n","print(\"Final model and checkpoint directories saved. Intermediate checkpoints deleted.\")\n","\n","if os.path.exists(checkpoint_path):\n","    shutil.rmtree(checkpoint_path)\n","    print(f\"Deleted entire checkpoint directory: {checkpoint_path}\")\n","os.makedirs(checkpoint_path, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1705637432313,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"tluIA7j4bZhb"},"outputs":[],"source":["# Function to initialize the Trainer for evaluation\n","def initialize_trainer_for_evaluation(model, training_args, eval_dataset):\n","    \"\"\"\n","    Initialize a Trainer object for model evaluation.\n","\n","    Args:\n","        model (PreTrainedModel): The pre-trained model to evaluate.\n","        training_args (TrainingArguments): Training arguments for evaluation.\n","        eval_dataset (Dataset): The evaluation dataset.\n","\n","    Returns:\n","        Trainer: A Trainer object for evaluation.\n","    \"\"\"\n","    return Trainer(\n","        model=model,\n","        args=training_args,\n","        eval_dataset=eval_dataset,\n","    )\n","\n","# Function to get the next available file name\n","def get_next_file_name(file_prefix):\n","    \"\"\"\n","    Get the next available file name by appending an index.\n","\n","    Args:\n","        file_prefix (str): The prefix for the file name.\n","\n","    Returns:\n","        str: The next available file name.\n","    \"\"\"\n","    index = 0\n","    while True:\n","        file_name = f\"{file_prefix}_{index}.json\"\n","        if not os.path.exists(file_name):\n","            return file_name\n","        index += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1705637432314,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"gSCuFEkN5Bw4"},"outputs":[],"source":["# Load the final model for evaluation after all epochs\n","final_model_path = all_checkpoint_paths[-1] if all_checkpoint_paths else None\n","\n","if final_model_path:\n","    print(\"Loading final model for evaluation from:\", final_checkpoint_directory)\n","    model = AutoModelForSequenceClassification.from_pretrained(final_checkpoint_directory, config=config)\n","    tokenizer = AutoTokenizer.from_pretrained(final_checkpoint_directory)\n","\n","    # Initialize the Trainer for final evaluation with the validation dataset\n","    eval_trainer = initialize_trainer_for_evaluation(model, training_args, val_dataset)\n","\n","    # Predict on the validation dataset\n","    print(\"Predicting on the validation dataset.\")\n","    predictions = eval_trainer.predict(val_dataset)\n","\n","    # Extract the predicted labels from the predictions\n","    final_predictions = np.argmax(predictions.predictions, axis=1)\n","    final_true_labels = val_dataset.get_labels()  # Get the true labels from the validation dataset\n","\n","    # Calculate final evaluation metrics\n","    final_metrics = calculate_evaluation_metrics(final_predictions, final_true_labels)\n","\n","    # Save final metrics with a sequentially numbered file name\n","    final_metrics_path = get_next_file_name(f\"{logs_path}/final_evaluation_metrics\")\n","    try:\n","        with open(final_metrics_path, 'w') as file:\n","            json.dump(final_metrics, file, indent=4)\n","            print(f\"Final Evaluation Metrics Saved as {final_metrics_path}\")\n","    except Exception as e:\n","        print(f\"An error occurred while saving the final metrics: {str(e)}\")\n","\n","    # Add the path to the final evaluation metrics file to the list for later use\n","    all_metrics_paths.append(final_metrics_path)\n","\n","    # Print the final evaluation metrics\n","    print(\"Final Evaluation Metrics:\")\n","    print(\"Accuracy:\", final_metrics['accuracy'])\n","    print(\"Precision:\", final_metrics['precision'])\n","    print(\"Recall:\", final_metrics['recall'])\n","    print(\"F1 Score:\", final_metrics['F1_score'])\n","    print(\"Confusion Matrix:\")\n","    print(final_metrics['confusion_matrix'])\n","    print(\"ROC AUC:\", final_metrics['ROC_AUC'])\n","\n","    # Print the last saved final metrics\n","    if os.path.exists(final_metrics_path):\n","        print(f\"Last Saved Final Metrics ({final_metrics_path}):\")\n","        with open(final_metrics_path, 'r') as file:\n","            last_saved_metrics = json.load(file)\n","            print(\"Accuracy:\", last_saved_metrics['accuracy'])\n","            print(\"Precision:\", last_saved_metrics['precision'])\n","            print(\"Recall:\", last_saved_metrics['recall'])\n","            print(\"F1 Score:\", last_saved_metrics['F1_score'])\n","            print(\"Confusion Matrix:\")\n","            print(last_saved_metrics['confusion_matrix'])\n","            print(\"ROC AUC:\", last_saved_metrics['ROC_AUC'])\n","else:\n","    print(\"No model checkpoint found for evaluation.\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/Di9mar/ada4b/blob/main/Wiki_Classification_2.ipynb","timestamp":1705637877793}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0886563dfef64517b2830aca9e761843":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"093d063d127846879a0ef654aa62333c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0961f4f8c9d541479d287784a4435936","placeholder":"​","style":"IPY_MODEL_79928b2f3b074291b4e68ef428aafae1","value":" 483/483 [00:00&lt;00:00, 23.4kB/s]"}},"0961f4f8c9d541479d287784a4435936":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c7e7f0e002543c7936104ec88ef89ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c07f242f8f6743efba7c594d36e4e012","placeholder":"​","style":"IPY_MODEL_ae4d9dedbdb34304acd0931f7837b1f4","value":"model.safetensors: 100%"}},"0e5a2d0ce53c46a2965f3e7aa01d28b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c18bedd594e54b708244427ef580781c","placeholder":"​","style":"IPY_MODEL_bc090c8c53b34fab8233a30d766947dd","value":"tokenizer_config.json: 100%"}},"12cdbd56e7f848e6a9df72c3dd2dc38f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97900e9795b94c2285b306d695fad939","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0886563dfef64517b2830aca9e761843","value":28}},"1b6c388243da41c58cdc3cc3ed3729f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"284f3fbfc53041c580c2765166311072":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f873e5aa492944049d4039593bedd22e","IPY_MODEL_c1d3f98480bb4ef2902e80cc456fb420","IPY_MODEL_bbad81ca2dcf43238e86b0becfb296ba"],"layout":"IPY_MODEL_c96e1789aaa4449ba03fba7b663f2a4b"}},"29bc44c2e9b641a7b4258521fdda0827":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f29474cb4eb49ca8c14f20b99b961ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f41f940f6b54a0a8a9d1088414a4ad7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32aa2fd53d22459d81a9b2181049900d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32dc9ea09af2412e8e1d6230cf085701":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a1155a215a6413292a6540cd351264c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ee48636612345cab59318136d6b0f11":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44ba4b54afd4437884f091275d519938":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"450a478aa475494f9c342ebf9f75e694":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef37286e51e142269681109636618c19","placeholder":"​","style":"IPY_MODEL_29bc44c2e9b641a7b4258521fdda0827","value":" 28.0/28.0 [00:00&lt;00:00, 1.62kB/s]"}},"49270fa05084478c9ae69c26d6a6dbcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d4cad4a3ba541a4bda30aa87fd34467":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6457d495913548c6a6ea09923e36e41a","placeholder":"​","style":"IPY_MODEL_1b6c388243da41c58cdc3cc3ed3729f0","value":" 268M/268M [00:02&lt;00:00, 104MB/s]"}},"4feab3a1edc64b05af0bde80439e57c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5881ff5cedf946b09b440ed8b6cb5268":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59a758cf5dc34bde89f77b852b7be585":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59f8964f18224a8bb2d28683158d6a07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6868385188f478f8f6294b6ae75bfa8","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a1155a215a6413292a6540cd351264c","value":483}},"5f09074ed4874d2bb181d95142d0ddfd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6457d495913548c6a6ea09923e36e41a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68f98b2a9af445f19fede336071d5db3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69230da3e92540ac88421f76cd669d3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e5a2d0ce53c46a2965f3e7aa01d28b3","IPY_MODEL_12cdbd56e7f848e6a9df72c3dd2dc38f","IPY_MODEL_450a478aa475494f9c342ebf9f75e694"],"layout":"IPY_MODEL_82e261a44e5443249b9dc51f37e62c60"}},"79928b2f3b074291b4e68ef428aafae1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80dc312638b34af6b835f7beeb8ad76a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82e261a44e5443249b9dc51f37e62c60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8475363f9a3e4e7f92f5e49786b5ca4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87e48c43555441cf8d75bdbc785f24fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59a758cf5dc34bde89f77b852b7be585","placeholder":"​","style":"IPY_MODEL_9f3dd424b6984361acc31b6e9a111ba4","value":" 232k/232k [00:00&lt;00:00, 3.17MB/s]"}},"9213b880c7f9410aa4b1bf6d70008806":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd6fb565203c4ff08d7b761456f7a11b","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68f98b2a9af445f19fede336071d5db3","value":267954768}},"97900e9795b94c2285b306d695fad939":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9babcbaca4ad41629b4162718822af13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ca5b2c10aee41aa8b8fa0dc261f8565":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9babcbaca4ad41629b4162718822af13","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6d16375fd9d4d589b964f532c416642","value":231508}},"9f3dd424b6984361acc31b6e9a111ba4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1c230300e3a4d1abdf5be4122d172cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7810b5f94314f2f8d3b3c906f7360c9","IPY_MODEL_59f8964f18224a8bb2d28683158d6a07","IPY_MODEL_093d063d127846879a0ef654aa62333c"],"layout":"IPY_MODEL_3ee48636612345cab59318136d6b0f11"}},"a7810b5f94314f2f8d3b3c906f7360c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80dc312638b34af6b835f7beeb8ad76a","placeholder":"​","style":"IPY_MODEL_32aa2fd53d22459d81a9b2181049900d","value":"config.json: 100%"}},"ae4d9dedbdb34304acd0931f7837b1f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbad81ca2dcf43238e86b0becfb296ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44ba4b54afd4437884f091275d519938","placeholder":"​","style":"IPY_MODEL_8475363f9a3e4e7f92f5e49786b5ca4c","value":" 466k/466k [00:00&lt;00:00, 10.1MB/s]"}},"bc090c8c53b34fab8233a30d766947dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd1e92c5583f4699af5170a91305e466":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc51a4fe4bb24e8c8783ee287ca43159","IPY_MODEL_9ca5b2c10aee41aa8b8fa0dc261f8565","IPY_MODEL_87e48c43555441cf8d75bdbc785f24fe"],"layout":"IPY_MODEL_2f29474cb4eb49ca8c14f20b99b961ce"}},"c07f242f8f6743efba7c594d36e4e012":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c18bedd594e54b708244427ef580781c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1d3f98480bb4ef2902e80cc456fb420":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1983b1bff9b48f8871ce1c403a8af94","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49270fa05084478c9ae69c26d6a6dbcf","value":466062}},"c6868385188f478f8f6294b6ae75bfa8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c96e1789aaa4449ba03fba7b663f2a4b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1983b1bff9b48f8871ce1c403a8af94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6d16375fd9d4d589b964f532c416642":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef37286e51e142269681109636618c19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f873e5aa492944049d4039593bedd22e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f41f940f6b54a0a8a9d1088414a4ad7","placeholder":"​","style":"IPY_MODEL_32dc9ea09af2412e8e1d6230cf085701","value":"tokenizer.json: 100%"}},"f890ff6050fb4e1da53d9ffe3843646d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c7e7f0e002543c7936104ec88ef89ee","IPY_MODEL_9213b880c7f9410aa4b1bf6d70008806","IPY_MODEL_4d4cad4a3ba541a4bda30aa87fd34467"],"layout":"IPY_MODEL_5f09074ed4874d2bb181d95142d0ddfd"}},"fc51a4fe4bb24e8c8783ee287ca43159":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4feab3a1edc64b05af0bde80439e57c0","placeholder":"​","style":"IPY_MODEL_5881ff5cedf946b09b440ed8b6cb5268","value":"vocab.txt: 100%"}},"fd6fb565203c4ff08d7b761456f7a11b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
