{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzkRq+wb3CkCH7DeaeJ52X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Di9mar/ada4b/blob/main/Evaluation_Multiple_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pop4rjwSvvyJ",
        "outputId": "98348f86-d1a2-4d5c-aae1-da93220c51fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed accelerate-0.26.1 datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15 transformers-4.36.2\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install datasets transformers[torch] --upgrade\n",
        "\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the 'drive' module from the 'google.colab' library\n",
        "# This module allows you to mount your Google Drive in the Colab environment.\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to '/content/drive'\n",
        "# This will make the Google Drive files accessible from within the Colab environment.\n",
        "# You'll be prompted to authenticate and grant necessary permissions.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FkubkSuv_n1",
        "outputId": "f2a35474-f8f0-4e64-e375-a92f94e1fd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining names for models and datafile\n",
        "current_model = ['wiki', 'essay', 'poetry', 'story']\n",
        "data_file = \"val_dataset\"\n",
        "\n",
        "# These variables store the paths to different directories and files.\n",
        "# Model path will be stored in an array called 'model_paths'\n",
        "base_path = \"/content/drive/My Drive/ColabData\"\n",
        "model_paths = []\n",
        "for element in current_model:\n",
        "  model_paths.append(f\"{base_path}/{element}\")\n",
        "\n",
        "csv_path = f\"{base_path}/{data_file}.csv\"\n",
        "logs_path = f\"{base_path}/logs\""
      ],
      "metadata": {
        "id": "C5UyUEJwv_pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the trained models and their corresponding tokenizer\n",
        "# Storing the models\n",
        "model_list = []\n",
        "\n",
        "# Storing the tokenizers\n",
        "tokenizer_list = []\n",
        "\n",
        "# For loop to load all models in model list in current enviroment\n",
        "for element in model_paths:\n",
        "    print(f\"Loading '{element}' model\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(element)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(element)\n",
        "\n",
        "    model_list.append(model)\n",
        "    tokenizer_list.append(tokenizer)\n",
        "\n",
        "    # Print the model configuration for reference\n",
        "    print(f\"Model Configuration:\\n{model.config}\")"
      ],
      "metadata": {
        "id": "dwEPFPvfxdh7",
        "outputId": "32e9f86b-66e0-402d-a95c-f9e153750849",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading '/content/drive/My Drive/ColabData/wiki' model\n",
            "Model Configuration:\n",
            "DistilBertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/My Drive/ColabData/wiki\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.36.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Loading '/content/drive/My Drive/ColabData/essay' model\n",
            "Model Configuration:\n",
            "DistilBertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/My Drive/ColabData/essay\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.36.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Loading '/content/drive/My Drive/ColabData/poetry' model\n",
            "Model Configuration:\n",
            "DistilBertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/My Drive/ColabData/poetry\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.36.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Loading '/content/drive/My Drive/ColabData/story' model\n",
            "Model Configuration:\n",
            "DistilBertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/My Drive/ColabData/story\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.36.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Chunk defines the dataset class\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "\n",
        "        # Tokenize the text on-the-fly\n",
        "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "        # Convert the encoding to a format suitable for PyTorch\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}  # Squeeze is used to remove batch dimension\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_labels(self):\n",
        "        return self.labels\n",
        "\n",
        "\n",
        "# Defines the function to Calculate Metrics\n",
        "def calculate_evaluation_metrics(predictions, true_labels):\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
        "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "    roc_auc = roc_auc_score(true_labels, predictions)  # For binary classification\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'F1_score': f1,\n",
        "        'confusion_matrix': conf_matrix.tolist(),\n",
        "        'ROC_AUC': roc_auc\n",
        "    }"
      ],
      "metadata": {
        "id": "p_5Tg6u1v_un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code loads data from a specified directory in Google Drive.\n",
        "try:\n",
        "    df = pd.read_csv(csv_path, delimiter=';')\n",
        "    load_success = True\n",
        "except Exception as e:\n",
        "    load_success = False\n",
        "    df = None\n",
        "    error_message = str(e)\n",
        "\n",
        "load_success, df if df is not None else error_message"
      ],
      "metadata": {
        "id": "8E4PgWgTv_wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing excess newline characters\n",
        "df['human'] = df['human'].str.replace(r'\\n+', '\\n')\n",
        "df['ai'] = df['ai'].str.replace(r'\\n+', '\\n')\n",
        "\n",
        "# Preparing the data for prediction evaluation\n",
        "labels = [0] * len(df['human']) + [1] * len(df['ai'])  # Adjust columns as per your data\n",
        "texts = df['human'].tolist() + df['ai'].tolist()  # Adjust columns as per your data\n",
        "dataset = TextDataset(texts, labels, tokenizer)\n",
        "\n",
        "# Initializing the Trainer for each model with a list, corresponding in length with the model list\n",
        "trainers = []\n",
        "for model, tokenizer in zip(model_list, tokenizer_list):\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "    trainers.append(trainer)"
      ],
      "metadata": {
        "id": "o1Vf8BmSv_zB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c419f12f-3ae0-4d92-a621-2338ed1fba89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-f08f75aed6c6>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['human'] = df['human'].str.replace(r'\\n+', '\\n')\n",
            "<ipython-input-38-f08f75aed6c6>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['ai'] = df['ai'].str.replace(r'\\n+', '\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, before predicting, the dataset will be tokenized row by row to check if the data is correcty formatted and set up for predictions\n",
        "successful_count = 0\n",
        "error_count = 0\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    try:\n",
        "        # Tokenizing each row of the text\n",
        "        encoding = tokenizer(row['human'], row['ai'], truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
        "        # Choosing next row after succesfully tokenizing one row\n",
        "        successful_count += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        error_count += 1\n",
        "        # Printing the error message and the problematic texts\n",
        "        print(f\"Error in row {idx}: {str(e)}\")\n",
        "        print(f\"Problematic 'human' text (row {idx}):\\n{row['human']}\\n\")\n",
        "        print(f\"Problematic 'ai' text (row {idx}):\\n{row['ai']}\\n\")\n",
        "\n",
        "# Printing the summary statistic at the\n",
        "print(f\"Total rows processed: {successful_count + error_count}\")\n",
        "print(f\"Successful tokenizations: {successful_count}\")\n",
        "print(f\"Tokenization errors: {error_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeGPVkZEUEDX",
        "outputId": "b316a115-2505-4979-9a6c-3a59cc424754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows processed: 15000\n",
            "Successful tokenizations: 15000\n",
            "Tokenization errors: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These two arrays will contain the prediction results for each model\n",
        "all_predictions = []\n",
        "all_metrics = []\n",
        "\n",
        "for trainer in trainers:\n",
        "    # Predicting on the dataset\n",
        "    print(f\"Predicting {trainer}\")\n",
        "    predictions = trainer.predict(dataset)\n",
        "    predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "    # Storing predictions in array list\n",
        "    all_predictions.append(predicted_labels)\n",
        "\n",
        "    # Calculating the models evaluation metrics\n",
        "    metrics = calculate_evaluation_metrics(predicted_labels, dataset.get_labels())\n",
        "    all_metrics.append(metrics)\n",
        "    print(metrics)"
      ],
      "metadata": {
        "id": "5-HxJWIWv_1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Printing the metrics for each model\n",
        "print(\"Final Evaluation Metrics:\")\n",
        "for i, metrics in enumerate(all_metrics):\n",
        "    print(f\"Model {i+1} Metrics:\")\n",
        "    print(\"Accuracy:\", metrics.get('accuracy', 'Not available'))\n",
        "    print(\"Precision:\", metrics.get('precision', 'Not available'))\n",
        "    print(\"Recall:\", metrics.get('recall', 'Not available'))\n",
        "    print(\"F1 Score:\", metrics.get('F1_score', 'Not available'))\n",
        "    print(\"Confusion Matrix:\\n\", metrics.get('confusion_matrix', 'Not available'))\n",
        "    print(\"ROC AUC:\", metrics.get('ROC_AUC', 'Not available'))\n",
        "    print(\"---------------------------------------\")"
      ],
      "metadata": {
        "id": "eiESIHY8v_3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaed0c88-804e-45ee-8284-598701c136ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Evaluation Metrics:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the base name for the data file without index extension\n",
        "data_file_base = os.path.basename(data_file).split('.')[0]\n",
        "\n",
        "# Saving the evaluation metrics for each model with specific model name and datafile name\n",
        "for model_name, metrics in zip(current_model, all_metrics):\n",
        "    # Define the file name for the metrics using model_name and data_file\n",
        "    metrics_file = f\"{logs_path}/evaluation_metrics_{model_name}_{data_file_base}.json\"\n",
        "\n",
        "    # Saving the evaluation metrics to drive folder\n",
        "    try:\n",
        "        with open(metrics_file, 'w') as file:\n",
        "            json.dump(metrics, file, indent=4)\n",
        "        print(f\"Evaluation metrics for '{model_name}' saved in {metrics_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving the metrics for '{model_name}': {str(e)}\")"
      ],
      "metadata": {
        "id": "WiPFfbHJv_5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32db365-931a-41d6-b050-76754cdcaef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics saved in /content/drive/My Drive/TEST/logs/evaluation_metrics_essay_story_data.json\n"
          ]
        }
      ]
    }
  ]
}