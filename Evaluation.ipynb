{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHY4KSMJ7ixxVM1Pg8JQcl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Di9mar/ada4b/blob/main/Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pop4rjwSvvyJ",
        "outputId": "58dbf260-5bd9-4941-d22b-dbd509bd3506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed accelerate-0.26.1 datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15 transformers-4.36.2\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install datasets transformers[torch] --upgrade\n",
        "\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the 'drive' module from the 'google.colab' library\n",
        "# This module allows you to mount your Google Drive in the Colab environment.\n",
        "# Make sure you have the necessary authorization to access your Drive.\n",
        "# If not already installed, you may need to install the 'google-colab' package.\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to '/content/drive'\n",
        "# This will make your Google Drive files accessible from within the Colab environment.\n",
        "# You'll be prompted to authenticate and grant necessary permissions.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FkubkSuv_n1",
        "outputId": "4387ee48-2542-4687-ffa7-680ed78c7e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "current_model = \"essay\"\n",
        "data_file = \"story_data\"\n",
        "\n",
        "# Define paths based on your original code\n",
        "base_path = \"/content/drive/My Drive/ColabData\"\n",
        "model_path = f\"{base_path}/{current_model}\"\n",
        "csv_path = f\"{base_path}/{data_file}.csv\"\n",
        "logs_path = f\"{base_path}/logs\""
      ],
      "metadata": {
        "id": "C5UyUEJwv_pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model and tokenizer\n",
        "print(f\"Loading '{current_model}' model\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "# Print the model configuration for reference\n",
        "print(f\"Model Configuration:\\n{model.config}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIPieZ4Sv_sK",
        "outputId": "737836aa-f21d-4079-a959-81e147c1ceb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'essay' model\n",
            "Model Configuration:\n",
            "DistilBertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/My Drive/TEST/essay\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.36.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset class\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "\n",
        "        # Tokenize the text on-the-fly\n",
        "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "        # Convert the encoding to a format suitable for PyTorch\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}  # Squeeze is used to remove batch dimension\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_labels(self):\n",
        "        return self.labels\n",
        "\n",
        "\n",
        "# Function to Calculate Metrics\n",
        "def calculate_evaluation_metrics(predictions, true_labels):\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
        "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "    roc_auc = roc_auc_score(true_labels, predictions)  # For binary classification\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'F1_score': f1,\n",
        "        'confusion_matrix': conf_matrix.tolist(),\n",
        "        'ROC_AUC': roc_auc\n",
        "    }"
      ],
      "metadata": {
        "id": "p_5Tg6u1v_un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new data\n",
        "try:\n",
        "    df = pd.read_csv(csv_path, delimiter=';')\n",
        "    load_success = True\n",
        "except Exception as e:\n",
        "    load_success = False\n",
        "    df = None\n",
        "    error_message = str(e)\n",
        "\n",
        "load_success, df if df is not None else error_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E4PgWgTv_wu",
        "outputId": "8102b87c-8fdc-4868-fa4e-a7f2c7f4ec64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True,\n",
              "                                                  human  \\\n",
              " 0    Chapter Text\\n\\n\\nThey’d just fired him.\\n\\n\\n...   \n",
              " 1    Stu wakes up in a coffin and thinks, fuck. Las...   \n",
              " 2    It was the holiday season in Bound Arlyn, and ...   \n",
              " 3    His eyes were so warm and intense on me that I...   \n",
              " 4    Ada: Salazar Castle: Bedroom:\\n\\n \\nI sat perc...   \n",
              " ..                                                 ...   \n",
              " 173  A letter laid in his hand. A date not even rea...   \n",
              " 174  Chapter Text\\n\\nDistrict One: Female- Valentin...   \n",
              " 175  Intak always keep an eye on Jiung. How he sudd...   \n",
              " 176  Once upon a time, in a small mountain town cal...   \n",
              " 177  “I don’t need you anymore.”\\n\\n\\n\\n I repeat t...   \n",
              " \n",
              "                                                     ai  \n",
              " 0    In a world where soulmates actually exists, wh...  \n",
              " 1    So i suddenly came up with this idea, what if ...  \n",
              " 2    Once upon a time it was an average day in the ...  \n",
              " 3    Bella sat there waiting, watching the clock. T...  \n",
              " 4    Smithers sat in the dimly-lit interrogation ro...  \n",
              " ..                                                 ...  \n",
              " 173  \\nI was born with the ability to transform int...  \n",
              " 174  \\nOnce upon a time, there was a young woman na...  \n",
              " 175  Magic and technology have coexisted for centur...  \n",
              " 176  The day started out like any other for 16-year...  \n",
              " 177  The world is a very different place than it wa...  \n",
              " \n",
              " [178 rows x 2 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove excess newline characters\n",
        "df['human'] = df['human'].str.replace(r'\\n+', '\\n')\n",
        "df['ai'] = df['ai'].str.replace(r'\\n+', '\\n')\n",
        "\n",
        "# Prepare the data\n",
        "labels = [0] * len(df['human']) + [1] * len(df['ai'])  # Adjust columns as per your data\n",
        "texts = df['human'].tolist() + df['ai'].tolist()  # Adjust columns as per your data\n",
        "dataset = TextDataset(texts, labels, tokenizer)\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "o1Vf8BmSv_zB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a6e691-5aec-4484-8a5c-f2b0b0ccb6ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-42ff40dda06b>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['human'] = df['human'].str.replace(r'\\n+', '\\n')\n",
            "<ipython-input-7-42ff40dda06b>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['ai'] = df['ai'].str.replace(r'\\n+', '\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "successful_count = 0\n",
        "error_count = 0\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    try:\n",
        "        # Tokenize the text\n",
        "        encoding = tokenizer(row['human'], row['ai'], truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
        "        successful_count += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        error_count += 1\n",
        "        # Print the error message and the problematic texts\n",
        "        print(f\"Error in row {idx}: {str(e)}\")\n",
        "        print(f\"Problematic 'human' text (row {idx}):\\n{row['human']}\\n\")\n",
        "        print(f\"Problematic 'ai' text (row {idx}):\\n{row['ai']}\\n\")\n",
        "\n",
        "# Print the summary at the end\n",
        "print(f\"Total rows processed: {successful_count + error_count}\")\n",
        "print(f\"Successful tokenizations: {successful_count}\")\n",
        "print(f\"Tokenization errors: {error_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeGPVkZEUEDX",
        "outputId": "bbe101d2-e1d4-436e-f984-677279fd539e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows processed: 178\n",
            "Successful tokenizations: 178\n",
            "Tokenization errors: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the new dataset\n",
        "predictions = trainer.predict(dataset)\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Evaluate the model\n",
        "metrics = calculate_evaluation_metrics(predicted_labels, dataset.get_labels())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "5-HxJWIWv_1I",
        "outputId": "b9ce37b6-0e07-41b5-d6c0-5eaf19adc484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the final evaluation metrics\n",
        "print(\"Final Evaluation Metrics:\")\n",
        "print(\"Accuracy:\", metrics['accuracy'])\n",
        "print(\"Precision:\", metrics['precision'])\n",
        "print(\"Recall:\", metrics['recall'])\n",
        "print(\"F1 Score:\", metrics['F1_score'])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(metrics['confusion_matrix'])\n",
        "print(\"ROC AUC:\", metrics['ROC_AUC'])"
      ],
      "metadata": {
        "id": "eiESIHY8v_3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d2602d-bc71-476d-f588-f3e75ffbb704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Evaluation Metrics:\n",
            "Accuracy: 0.5\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n",
            "Confusion Matrix:\n",
            "[[178, 0], [178, 0]]\n",
            "ROC AUC: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file name for the metrics using current_model and data_file\n",
        "metrics_file = f\"{logs_path}/evaluation_metrics_{current_model}_{os.path.basename(data_file).split('.')[0]}.json\"\n",
        "\n",
        "# Save the evaluation metrics\n",
        "try:\n",
        "    with open(metrics_file, 'w') as file:\n",
        "        json.dump(metrics, file, indent=4)\n",
        "    print(f\"Evaluation metrics saved in {metrics_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the metrics: {str(e)}\")"
      ],
      "metadata": {
        "id": "WiPFfbHJv_5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32db365-931a-41d6-b050-76754cdcaef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics saved in /content/drive/My Drive/TEST/logs/evaluation_metrics_essay_story_data.json\n"
          ]
        }
      ]
    }
  ]
}